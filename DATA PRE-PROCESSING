from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
# Load the Iris dataset
data = load_iris()
X = data.data # Features
y = data.target # Labels
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
# Output preprocessed data shapes and a sample
print("Training feature shape:", X_train.shape)
print("Testing feature shape:", X_test.shape)
print("First training example after scaling:", X_train[0])
